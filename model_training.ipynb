{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structural-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    ShuffleSplit,\n",
    "    StratifiedShuffleSplit,\n",
    "    GroupShuffleSplit,\n",
    "    cross_val_predict,\n",
    "    cross_val_score,\n",
    ")\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "\n",
    "from gensim.sklearn_api import D2VTransformer\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import topcoder_mongo as DB\n",
    "import topcoder_ml as TML\n",
    "import static_var as S\n",
    "import util as U\n",
    "\n",
    "sns.set(\n",
    "    rc={\n",
    "        'axes.facecolor':'#121212',\n",
    "        'figure.facecolor':'#121212',\n",
    "        'text.color': 'white',\n",
    "        'axes.titlecolor': 'white',\n",
    "        'axes.labelcolor': 'white',\n",
    "        'xtick.color': 'white',\n",
    "        'ytick.color': 'white',\n",
    "        'figure.autolayout': True,\n",
    "    },\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-signal",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-manhattan",
   "metadata": {},
   "source": [
    "### Get processed training data\n",
    "\n",
    "The feature columns are composed as follow:\n",
    "\n",
    "1. $d_0, d_1, d_2 ~ d_5 $: Numeric features `duration`, `num_of_competing_challenges`, `softmax_c1` to `softmax_c4`;\n",
    "2. $d_6, d_7 $: Categorical features `project_id` and `sub_track`;\n",
    "3. $d_8 - d_{107} $: One Hot Encoded tag and tag combination;\n",
    "4. $d_{108} - d_{207} $: Document vector for challenge description text representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-houston",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature, target = TML.get_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-drunk",
   "metadata": {},
   "source": [
    "### Different `random_state` when do `train_test_split`\n",
    "\n",
    "Due to the imbalanced distribution of trianing target (`top2_prize`), when randomly split the training and testing data set, different random seeding will result in flucuated trianing and testing score.\n",
    "\n",
    "Below is the demonstration of different `random_state` that result in different performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "random_states = [0, 21, 42, None]\n",
    "result = []\n",
    "for random_state in random_states:\n",
    "    (\n",
    "        feature_train,\n",
    "        feature_test,\n",
    "        target_train,\n",
    "        target_test,\n",
    "    ) = train_test_split(feature, target, test_size=0.3, random_state=random_state)\n",
    "    \n",
    "    train_score = np.abs(np.mean(cross_val_score(\n",
    "        TML.construct_training_pipeline(),\n",
    "        feature_train,\n",
    "        target_train.to_numpy().reshape(-1),\n",
    "        scoring=make_scorer(TML.mean_magnitude_of_relative_error, greater_is_better=False),\n",
    "        cv=ShuffleSplit(n_splits=10, test_size=0.3, random_state=42),\n",
    "    )))\n",
    "    \n",
    "    test_est = TML.construct_training_pipeline()\n",
    "    test_est.fit(feature_train, target_train.to_numpy().reshape(-1))\n",
    "    test_pred = test_est.predict(feature_test)\n",
    "    \n",
    "    test_score = TML.mean_magnitude_of_relative_error(target_test.to_numpy().reshape(-1), test_pred)\n",
    "    \n",
    "    result.append({'random_state': str(random_state), 'train_score': train_score, 'test_score': test_score})\n",
    "\n",
    "pd.DataFrame.from_records(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "score = cross_val_score(\n",
    "    TML.construct_training_pipeline(),\n",
    "    feature,\n",
    "    target.to_numpy().reshape(-1),\n",
    "    scoring=make_scorer(TML.mean_magnitude_of_relative_error, greater_is_better=False),\n",
    "    cv=ShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    ")\n",
    "np.abs(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "est = TML.construct_training_pipeline()\n",
    "est.fit(feature_train, target_train.to_numpy().reshape(-1))\n",
    "pred = est.predict(feature_test)\n",
    "\n",
    "TML.mean_magnitude_of_relative_error(target_test.to_numpy().reshape(-1), pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perfect-breed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impt = pd.DataFrame(est['gbr'].feature_importances_).rename(columns={0: 'importance'}, index=dict(enumerate(feature.columns.tolist())))\n",
    "# impt.sort_values('importance', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-horizon",
   "metadata": {},
   "source": [
    "### Use `cross_validate_predict` to get the prediction of all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "est_for_all = TML.construct_training_pipeline()\n",
    "pred = cross_val_predict(est_for_all, feature, target.to_numpy().reshape(-1), cv=10)\n",
    "\n",
    "all_data_result = pd.concat([target.reset_index(), pd.DataFrame(pred)], axis=1).rename(columns={0: 'pred'})\n",
    "all_data_result['mae'] = all_data_result['top2_prize'] - all_data_result['pred']\n",
    "all_data_result['mre'] = all_data_result['mae'].abs() / all_data_result['top2_prize']\n",
    "all_data_result['mre'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-lawyer",
   "metadata": {},
   "source": [
    "### Iterate over multiple learning algorithms for training score and testing score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false --no-raise-error\n",
    "estimator_lst = [\n",
    "    (GradientBoostingRegressor, dict(random_state=42)),\n",
    "    (RandomForestRegressor, dict(random_state=42)),\n",
    "    (LinearRegression, {}),\n",
    "    (BayesianRidge, {}),\n",
    "    (SVR, {}),\n",
    "]\n",
    "\n",
    "result = []\n",
    "for est, estp in estimator_lst:\n",
    "    print('Training', est.__name__)\n",
    "    train_score = np.abs(np.mean(cross_val_score(\n",
    "        TML.construct_training_pipeline(estimator=est, est_param=estp),\n",
    "        feature_train,\n",
    "        target_train.to_numpy().reshape(-1),\n",
    "        scoring=make_scorer(TML.mean_magnitude_of_relative_error, greater_is_better=False),\n",
    "        cv=10, # ShuffleSplit(n_splits=10, test_size=0.3, random_state=42)\n",
    "    )))\n",
    "    \n",
    "    estimator = TML.construct_training_pipeline(estimator=est, est_param=estp)\n",
    "    estimator.fit(feature_train, target_train.to_numpy().reshape(-1))\n",
    "    test_pred = estimator.predict(feature_test)\n",
    "\n",
    "    test_score = TML.mean_magnitude_of_relative_error(target_test.to_numpy().reshape(-1), test_pred)\n",
    "    \n",
    "    result.append({'estimator': est.__name__, 'train_score': train_score, 'test_score': test_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrow-cheese",
   "metadata": {},
   "source": [
    "## Evaluate model using only partial of feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some pipelime function to run for training pipeline\n",
    "def construct_metadata_pipeline():\n",
    "    \"\"\" Construct pipeline for metadata features.\"\"\"\n",
    "    return Pipeline([\n",
    "        ('col', ColumnTransformer([\n",
    "            ('standardization', StandardScaler(), ['duration'])\n",
    "        ], remainder='passthrough')),\n",
    "        ('gbr', GradientBoostingRegressor(random_state=42)),\n",
    "    ])\n",
    "    \n",
    "def construct_global_context_pipeline():\n",
    "    \"\"\" Construct pipeline for global context feature.\"\"\"\n",
    "    return Pipeline([\n",
    "        ('std', StandardScaler()),\n",
    "        ('gbr', GradientBoostingRegressor(random_state=42)),\n",
    "    ])\n",
    "\n",
    "def construct_tag_feature_pipeline():\n",
    "    \"\"\" Construct pipeline for tag softmax and one-hot encoded.\"\"\"\n",
    "    return Pipeline([\n",
    "        ('col', ColumnTransformer([\n",
    "            ('standardization', StandardScaler(), S.TAG_SOFTMAX_COLUMNS)\n",
    "        ], remainder='passthrough')),\n",
    "        ('gbr', GradientBoostingRegressor(random_state=42)),\n",
    "    ])\n",
    "\n",
    "def construct_doc2vec_pipeline():\n",
    "    \"\"\" Construct pipeline for doc2vec model transformer.\"\"\"\n",
    "    def preprocess_text(df):\n",
    "        return df['processed_paragraph'].apply(simple_preprocess).to_list()\n",
    "    \n",
    "    return Pipeline([\n",
    "        ('preprocess_text', FunctionTransformer(preprocess_text)),\n",
    "        ('doc2vec', D2VTransformer(size=100, min_count=5, iter=10)),\n",
    "        ('gbr', GradientBoostingRegressor(random_state=42)),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-brazil",
   "metadata": {},
   "source": [
    "### Get `top2prize` target along with the limited scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "copyrighted-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_prize = (pd.DataFrame\n",
    "                   .from_records(DB.TopcoderMongo.run_feature_aggregation([\n",
    "                       {'$project': {'_id': False, 'id': True, 'top2_prize': True}}\n",
    "                   ]))\n",
    "                   .set_index('id'))\n",
    "\n",
    "challenge_by_project_scale = (pd.DataFrame\n",
    "                              .from_records(DB.TopcoderMongo.get_project_scale([0, 10]))\n",
    "                              .set_index('tag')\n",
    "                              .loc['>=10', 'challenge_lst'])\n",
    "low, high = challenge_prize['top2_prize'].quantile(0.05), challenge_prize['top2_prize'].quantile(0.95)\n",
    "\n",
    "challenge_prize = challenge_prize.loc[\n",
    "    (challenge_prize['top2_prize'] >= low) &\n",
    "    (challenge_prize['top2_prize'] <= high) &\n",
    "    challenge_prize.index.isin(challenge_by_project_scale)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-aquatic",
   "metadata": {},
   "source": [
    "### Use only metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continental-contamination",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\n",
    "    {'$project': {'_id': False, 'id': True, 'metadata': True}}\n",
    "]\n",
    "\n",
    "metadata = (pd.DataFrame\n",
    "            .from_records(challenge_prize\n",
    "                          .join(pd.DataFrame\n",
    "                                .from_records(DB.TopcoderMongo.run_feature_aggregation(query))\n",
    "                                .set_index('id'))\n",
    "                          .pop('metadata'),\n",
    "                          index=challenge_prize.index,\n",
    "                          columns=S.META_DATA_COLUMNS))\n",
    "\n",
    "metadata_score = np.abs(np.mean(cross_val_score(\n",
    "    construct_metadata_pipeline(), metadata, challenge_prize.to_numpy().reshape(-1),\n",
    "    scoring=make_scorer(TML.mean_magnitude_of_relative_error, greater_is_better=False),\n",
    "    cv=ShuffleSplit(n_splits=10, test_size=0.3, random_state=42),\n",
    ")))\n",
    "metadata_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-beads",
   "metadata": {},
   "source": [
    "### Use only Global Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-circuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\n",
    "    {'$project': {\n",
    "        '_id': False, 'id': True,\n",
    "        **{col: True for col in S.GLOBAL_CONTEXT_COLUMNS}\n",
    "    }}\n",
    "]\n",
    "\n",
    "global_context = (challenge_prize\n",
    "                  .join(\n",
    "                      pd.DataFrame\n",
    "                      .from_records(DB.TopcoderMongo.run_feature_aggregation(query))\n",
    "                      .set_index('id'))\n",
    "                  .reindex(S.GLOBAL_CONTEXT_COLUMNS, axis=1))\n",
    "\n",
    "global_context_score = np.abs(np.mean(cross_val_score(\n",
    "    construct_global_context_pipeline(),\n",
    "    global_context,\n",
    "    challenge_prize.to_numpy().reshape(-1),\n",
    "    scoring=make_scorer(TML.mean_magnitude_of_relative_error, greater_is_better=False),\n",
    "    cv=ShuffleSplit(n_splits=10, test_size=0.3, random_state=42),\n",
    ")))\n",
    "global_context_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-maine",
   "metadata": {},
   "source": [
    "### Use only Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-survivor",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\n",
    "    {'$project': {\n",
    "        '_id': False,\n",
    "        'id': True,\n",
    "        'vector': {\n",
    "            '$concatArrays': [\n",
    "                f'$softmax_dim{S.CHALLENGE_TAG_OHE_DIM}',\n",
    "                f'$one_hot_dim{S.CHALLENGE_TAG_OHE_DIM}',\n",
    "            ]\n",
    "        },\n",
    "    }}\n",
    "]\n",
    "\n",
    "tags = pd.DataFrame.from_records(\n",
    "    challenge_prize\n",
    "    .join(pd.DataFrame\n",
    "          .from_records(DB.TopcoderMongo.run_feature_aggregation(query))\n",
    "          .set_index('id'))\n",
    "    .pop('vector'),\n",
    "    index=challenge_prize.index,\n",
    "    columns=S.TAG_SOFTMAX_COLUMNS + S.TAG_OHE_COLUMNS,\n",
    ")\n",
    "\n",
    "tags_score = np.abs(np.mean(cross_val_score(\n",
    "    construct_tag_feature_pipeline(), tags, challenge_prize.to_numpy().reshape(-1),\n",
    "    scoring=make_scorer(TML.mean_magnitude_of_relative_error, greater_is_better=False),\n",
    "    cv=ShuffleSplit(n_splits=10, test_size=0.3, random_state=42),\n",
    ")))\n",
    "tags_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "given-trailer",
   "metadata": {},
   "source": [
    "### Use only Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge_description = (challenge_prize\n",
    "                         .join(pd.DataFrame\n",
    "                               .from_records(DB.TopcoderMongo.get_challenge_description())\n",
    "                               .set_index('id'))\n",
    "                         .pop('processed_paragraph')\n",
    "                         .to_frame())\n",
    "\n",
    "challenge_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "(challenge_description.index == challenge_prize.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corrected-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2v_score = np.abs(np.mean(cross_val_score(\n",
    "    construct_doc2vec_pipeline(),\n",
    "    challenge_description,\n",
    "    challenge_prize.to_numpy().reshape(-1),\n",
    "    scoring=make_scorer(TML.mean_magnitude_of_relative_error, greater_is_better=False),\n",
    "    cv=ShuffleSplit(n_splits=10, test_size=0.3, random_state=42),\n",
    ")))\n",
    "d2v_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-macedonia",
   "metadata": {},
   "source": [
    "## Difference of dimensions for Tags OHE and Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclusion_df = pd.read_json('./cross_validation_result.json')\n",
    "exclusion_df['excluded_metadata'] = exclusion_df['excluded_metadata'].apply(lambda l: ''.join(l))\n",
    "exclusion_df['excluded_global_context'] = exclusion_df['excluded_global_context'].apply(lambda l: ''.join(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-uzbekistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension_change = exclusion_df.loc[\n",
    "    ~exclusion_df['excluded_global_context'].astype(bool) &\n",
    "    ~exclusion_df['excluded_metadata'].astype(bool)\n",
    "].reindex(columns=['tag_ohe_dimension', 'doc2vec_dimension', 'mmre']).round(3)\n",
    "\n",
    "ohe_by_d2v = dimension_change.pivot(index='tag_ohe_dimension', columns='doc2vec_dimension', values='mmre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_by_d2v.max().max(), ohe_by_d2v.min().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-montreal",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10), dpi=200)\n",
    "\n",
    "sns.heatmap(\n",
    "    data=ohe_by_d2v, vmin=0.35, vmax=0.358,\n",
    "    square=True,\n",
    "    cmap=sns.diverging_palette(125, 25, as_cmap=True),\n",
    "    cbar=False,\n",
    "    annot=ohe_by_d2v, fmt='.3f',\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Doc2Vec Dimension')\n",
    "ax.set_ylabel('Challenge Tags OHE Dimension')\n",
    "ax.xaxis.tick_top()\n",
    "ax.tick_params(length=0)\n",
    "ax.xaxis.set_label_position('top')\n",
    "\n",
    "fig.savefig('../../presentation/presentation8/dimension_change.png', dpi='figure', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata leave one out\n",
    "(exclusion_df\n",
    " .loc[\n",
    "     exclusion_df['excluded_global_context'].astype(bool) |\n",
    "     (\n",
    "         (exclusion_df['excluded_metadata'] == '') &\n",
    "         (exclusion_df['excluded_global_context'] == '') &\n",
    "         (exclusion_df['tag_ohe_dimension'] == 100) &\n",
    "         (exclusion_df['doc2vec_dimension'] == 100)\n",
    "     )\n",
    " ]\n",
    " .reindex(columns=['excluded_global_context', 'mmre'])\n",
    " .reset_index(drop=True)\n",
    " .round(3)\n",
    " .to_clipboard(excel=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-press",
   "metadata": {},
   "source": [
    "## Evaluate model using Timeseries split\n",
    "\n",
    "For every month of challenge, predict the prize using the model trained by previous months data.\n",
    "The month window are `[3, 6, 9, 12]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-ensemble",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_result_dct = {}\n",
    "for train_time_span in [1, 3, 6, 9, 12]:\n",
    "    time_result_dct[train_time_span] = TML.cross_validation_with_time_window(feature, target, train_time_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-layout",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_result = pd.concat([\n",
    "    pd.DataFrame(result).rename(columns=dict(enumerate(['ts', tw]))).set_index('ts')\n",
    "    for tw, result in time_result_dct.items()\n",
    "], axis=1).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nonprofit-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 6.67), dpi=200)\n",
    "\n",
    "sns.lineplot(\n",
    "    data=ts_result,\n",
    "    lw=2.5,\n",
    "    ax=ax\n",
    ")\n",
    "sns.despine(ax=ax, left=True, bottom=True)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.xaxis.grid(False)\n",
    "ax.yaxis.grid(True, color='w', alpha=0.5)\n",
    "\n",
    "ax.set_title('Monthly MMRE with different time window')\n",
    "ax.set_xlabel('Month')\n",
    "ax.set_ylabel('MMRE')\n",
    "\n",
    "ax.axhline(0.354, color='red', alpha=0.85)\n",
    "ax.text(ax.get_xticks()[1] - 85, 0.36, 'baseline', color='red', alpha=0.85)\n",
    "fig.savefig('../../presentation/presentation8/monthly_mmre_line.png', dpi='figure', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bibliographic-requirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8), dpi=200)\n",
    "\n",
    "flierprops = {'marker': 'o', 'markerfacecolor': 'white', 'markeredgewidth': 0.5, 'markersize': 2.5}\n",
    "sns.boxplot(\n",
    "    data=ts_result,\n",
    "    linewidth=0.8,\n",
    "    flierprops=flierprops,\n",
    "    boxprops=dict(edgecolor='white'),\n",
    "    medianprops=dict(color='white'),\n",
    "    whiskerprops=dict(color='white'),\n",
    "    capprops=dict(color='white'),\n",
    "    width=0.618,\n",
    "    ax=ax\n",
    ")\n",
    "sns.despine(ax=ax, left=True)\n",
    "ax.yaxis.grid(True, alpha=0.5)\n",
    "ax.set_ylabel('MMRE')\n",
    "ax.set_xlabel('Time Window')\n",
    "\n",
    "fig.savefig('../../presentation/presentation8/monthly_mmre_box.png', dpi='figure', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-closing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TopcoderPricingResearch2021",
   "language": "python",
   "name": "topcoderpricingresearch2021"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
